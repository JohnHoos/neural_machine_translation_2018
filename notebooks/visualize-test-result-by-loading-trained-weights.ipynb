{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "import rnn_encoder_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n",
      "Most common source vocabs: [('là', 8210), ('tôi', 3628), ('không', 3530), ('Và', 3413), ('một', 3290), ('có', 2911), ('đó', 2883), ('Tôi', 2827), ('của', 2605), ('này', 2532)]\n",
      "Source vocab size: 6495\n",
      "Most common english vocabs: [('the', 10506), ('it', 7023), ('and', 6401), ('&apos;s', 6272), ('a', 5965), ('to', 5712), ('i', 5688), ('is', 5612), ('you', 5432), ('of', 4902)]\n",
      "English vocab size: 5897\n",
      "0 <unk>\n",
      "0 <unk>\n",
      "1 <pad>\n",
      "1 <pad>\n",
      "2 2\n",
      "2 2\n",
      "3 3\n",
      "3 3\n",
      "4 là\n",
      "4 the\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jp4989/anaconda3/envs/nlpclass/lib/python3.6/site-packages/torchtext/data/field.py:321: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(arr, volatile=not train), lengths\n",
      "/home/jp4989/anaconda3/envs/nlpclass/lib/python3.6/site-packages/torchtext/data/field.py:322: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(arr, volatile=not train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, step: 0, average loss for current epoch: 2.629408836364746, batch loss: 2.629408836364746, average bleu for current epoch: 1.2449052797300484, batch bleu: 1.2449052797300484\n",
      "test done. average loss for current epoch: 2.981989647894083, average bleu for current epoch: 0.18820189938985932\n"
     ]
    }
   ],
   "source": [
    "parser = rnn_encoder_decoder.rnn_encoder_decoder_argparser()\n",
    "args = parser.parse_args([]) # use default settings\n",
    "args.source_lang = 'vi'\n",
    "args.data = '../data/short-sentences-vi-en/'\n",
    "args.num_encoder_layers = 2\n",
    "args.num_decoder_layers = 2\n",
    "args.test = True\n",
    "# load best weight of this experiment\n",
    "args.model_weights_path = '../model_weights/short/3'\n",
    "loss, bleu, test_reference_list, translation_output_list = rnn_encoder_decoder.run(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('thank you', 'thank you appreciate')\n",
      "('oh my god', 'me me me me')\n",
      "('all right let &apos;s go', 'need want to learn able we')\n",
      "('hey why not', 'knows doesn doesn &apos;t')\n",
      "('is that all', 'saying he cares fine')\n",
      "('thank you very much', 'thanks you very much much')\n",
      "('we love innovation', 'we kept up up')\n",
      "('it would be unconscionable', 'however that turns thing isn')\n",
      "('we &apos;re constantly running into each other', 'we &apos;re lots types types types types types')\n",
      "('we &apos;ve been disconnected', 'why we need we need')\n",
      "('i don &apos;t know', 'i couldn never know sure')\n",
      "('my hunches again', 'third project jones is')\n",
      "('go home to where', 'many many many reasons happening')\n",
      "('we were poor', 'are these kinds of')\n",
      "('this is bjorn sundin', 'paul de attacks attacks anesthesia')\n",
      "('this is stephen watt', 'six arctic voices voices voices')\n",
      "('this is alfred gonzalez', 'paul de attacks attacks anesthesia')\n",
      "('these guys make money', 'manias happier needs happier consistency')\n",
      "('thank you', 'h thank thank')\n",
      "('pretty simple', 'simple simple simple')\n",
      "('okay', 'okay okay')\n",
      "('ohhhhh wowwww', 'paul de attacks')\n",
      "('it &apos;s true', 'looks looks amazing easy')\n",
      "('1,000 very good', 'incredible incredible incredible incredible')\n",
      "('all right', 'okay okay okay')\n",
      "('the first cut', 'two year weeks year')\n",
      "('we love entertainment', 'out of course goes')\n",
      "('thank you', 'robbie thank thank')\n",
      "('no', 'no no')\n",
      "('ohhhh', 'mmm through')\n",
      "('wooo', 'mmm through')\n",
      "('thank you', 'robbie thank thank')\n"
     ]
    }
   ],
   "source": [
    "for pair in zip(test_reference_list[0], translation_output_list[0]):\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n",
      "Most common source vocabs: [('là', 8210), ('tôi', 3628), ('không', 3530), ('Và', 3413), ('một', 3290), ('có', 2911), ('đó', 2883), ('Tôi', 2827), ('của', 2605), ('này', 2532)]\n",
      "Source vocab size: 6495\n",
      "Most common english vocabs: [('the', 10506), ('it', 7023), ('and', 6401), ('&apos;s', 6272), ('a', 5965), ('to', 5712), ('i', 5688), ('is', 5612), ('you', 5432), ('of', 4902)]\n",
      "English vocab size: 5897\n",
      "0 <unk>\n",
      "0 <unk>\n",
      "1 <pad>\n",
      "1 <pad>\n",
      "2 2\n",
      "2 2\n",
      "3 3\n",
      "3 3\n",
      "4 là\n",
      "4 the\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jp4989/anaconda3/envs/nlpclass/lib/python3.6/site-packages/torchtext/data/field.py:321: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(arr, volatile=not train), lengths\n",
      "/home/jp4989/anaconda3/envs/nlpclass/lib/python3.6/site-packages/torchtext/data/field.py:322: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(arr, volatile=not train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, step: 0, average loss for current epoch: 2.618600845336914, batch loss: 2.618600845336914, average bleu for current epoch: 0.07508785669171106, batch bleu: 0.07508785669171106\n",
      "test done. average loss for current epoch: 2.944284950650327, average bleu for current epoch: 0.05358892714533567\n",
      "('thank you', 'shining gentlemen joining')\n",
      "('oh my god', 'god oh god god')\n",
      "('all right let &apos;s go', 'let starting &apos;ll begin visit broadmoor')\n",
      "('hey why not', 'why why why aren')\n",
      "('is that all', 'sees hopefully wrong telling')\n",
      "('thank you very much', 'tm mizzone mizzone much daniel')\n",
      "('we love innovation', 'wanted wanted talking computers')\n",
      "('it would be unconscionable', 'this strategy became extremely extremely')\n",
      "('we &apos;re constantly running into each other', 'polio transport only dropped sexual consciousness sexual visible')\n",
      "('we &apos;ve been disconnected', 'therefore lived lived walked disappeared')\n",
      "('i don &apos;t know', 'haven didn recommend ashamed anymore')\n",
      "('my hunches again', 'instance example called straw')\n",
      "('go home to where', 'context context context within verbs')\n",
      "('we were poor', 'our catch excited studies')\n",
      "('this is bjorn sundin', 'sebastian hid thunder ge poetry')\n",
      "('this is stephen watt', 'david 23 lee lee charles')\n",
      "('this is alfred gonzalez', 'pranav rose aria invisible rose')\n",
      "('these guys make money', 'joe condoms condoms condoms condoms')\n",
      "('thank you', 'ladies moore brian')\n",
      "('pretty simple', 'complicated simple important')\n",
      "('okay', 'okay yep')\n",
      "('ohhhhh wowwww', 'kiran bleeding cooking')\n",
      "('it &apos;s true', 'seriously seriously seriously seriously')\n",
      "('1,000 very good', 'breathing relatively phenomenal theory')\n",
      "('all right', 'ag happening happening')\n",
      "('the first cut', 'first first days joined')\n",
      "('we love entertainment', 'loving responsible environment worse')\n",
      "('thank you', 'thanks scott hack')\n",
      "('no', 'no photoshop')\n",
      "('ohhhh', 'waste fiber')\n",
      "('wooo', 'deny borders')\n",
      "('thank you', 'moore moore hack')\n"
     ]
    }
   ],
   "source": [
    "# load specific epoch of this experiment, if saved\n",
    "args.model_weights_path = '../model_weights/short/3/6'\n",
    "loss, bleu, test_reference_list, translation_output_list = rnn_encoder_decoder.run(args)\n",
    "for pair in zip(test_reference_list[0], translation_output_list[0]):\n",
    "    print(pair)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlpclass]",
   "language": "python",
   "name": "conda-env-nlpclass-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
