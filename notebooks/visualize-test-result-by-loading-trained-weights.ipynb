{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "import rnn_encoder_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n",
      "Most common source vocabs: [('là', 8210), ('tôi', 3628), ('không', 3530), ('Và', 3413), ('một', 3290), ('có', 2911), ('đó', 2883), ('Tôi', 2827), ('của', 2605), ('này', 2532)]\n",
      "Source vocab size: 6495\n",
      "Most common english vocabs: [('the', 10506), ('it', 7023), ('and', 6401), ('&apos;s', 6272), ('a', 5965), ('to', 5712), ('i', 5688), ('is', 5612), ('you', 5432), ('of', 4902)]\n",
      "English vocab size: 5897\n",
      "0 <unk>\n",
      "0 <unk>\n",
      "1 <pad>\n",
      "1 <pad>\n",
      "2 2\n",
      "2 2\n",
      "3 3\n",
      "3 3\n",
      "4 là\n",
      "4 the\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jp4989/anaconda3/envs/nlpclass/lib/python3.6/site-packages/torchtext/data/field.py:321: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(arr, volatile=not train), lengths\n",
      "/home/jp4989/anaconda3/envs/nlpclass/lib/python3.6/site-packages/torchtext/data/field.py:322: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(arr, volatile=not train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, step: 0, average loss for current epoch: 2.613800048828125, batch loss: 2.613800048828125, average bleu for current epoch: 1.2449052797300484, batch bleu: 1.2449052797300484\n",
      "test done. average loss for current epoch: 2.981459045845101, average bleu for current epoch: 0.19584494767913876\n"
     ]
    }
   ],
   "source": [
    "parser = rnn_encoder_decoder.rnn_encoder_decoder_argparser()\n",
    "args = parser.parse_args([]) # use default settings\n",
    "args.source_lang = 'vi'\n",
    "args.data = '../data/short-sentences-vi-en/'\n",
    "args.num_encoder_layers = 2\n",
    "args.num_decoder_layers = 2\n",
    "args.test = True\n",
    "# load best weight of this experiment\n",
    "args.model_weights_path = '../model_weights/short/3'\n",
    "loss, bleu, test_source_list, test_reference_list, translation_output_list = rnn_encoder_decoder.run(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Cảm_ơn các bạn', 'thank you', 'thank you appreciate')\n",
      "('Ôi chúa ơi', 'oh my god', 'me me me me')\n",
      "('Chúng_ta bắt_đầu nào', 'all right let &apos;s go', 'need want us learn we learn')\n",
      "('Ồ tại_sao không', 'hey why not', 'knows doesn doesn &apos;t')\n",
      "('đọc xong chứ', 'is that all', 'saying he cares fine')\n",
      "('Cám_ơn rất nhiều', 'thank you very much', 'thanks you very much much')\n",
      "('Chúng_ta thích cải_tiến', 'we love innovation', 'we kept up up')\n",
      "('Như_thế quá vô_lương_tâm', 'it would be unconscionable', 'however that turns thing dry')\n",
      "('chúng_ta không_ngừng mâu_thuẫn', 'we &apos;re constantly running into each other', 'we &apos;re lots types types types countries than')\n",
      "('thế_là chúng_ta tách_biệt', 'we &apos;ve been disconnected', 'why we need need need')\n",
      "('Tôi không biết', 'i don &apos;t know', 'i couldn never know sure')\n",
      "('Lại là linh_cảm', 'my hunches again', 'third first project called')\n",
      "('Về nhà_ở đâu', 'go home to where', 'many many many reasons happening')\n",
      "('Chúng_tôi rất nghèo', 'we were poor', 'are these kinds of')\n",
      "('Bjorn Sundin', 'this is bjorn sundin', 'paul de attacks attacks anesthesia')\n",
      "('Stephen Watt', 'this is stephen watt', 'dan voices voices voices voices')\n",
      "('Alfred Gonzalez', 'this is alfred gonzalez', 'paul november attacks attacks anesthesia')\n",
      "('Kiếm tiền', 'these guys make money', 'manias happier needs happier consistency')\n",
      "('Xin cảm_ơn', 'thank you', 'h thank thank')\n",
      "('Khá đơn_giản', 'pretty simple', 'simple simple simple')\n",
      "('Được rồi', 'okay', 'okay okay')\n",
      "('Ohhhhh wowwww', 'ohhhhh wowwww', 'paul de attacks')\n",
      "('Thật đấy', 'it &apos;s true', 'looks looks amazing easy')\n",
      "('1000 tuyệt_vời', '1,000 very good', 'incredible incredible incredible incredible')\n",
      "('Được rồi', 'all right', 'okay okay okay')\n",
      "('Đầu_tiên Cắt_giảm', 'the first cut', 'two audience weeks weeks')\n",
      "('thích giải_trí', 'we love entertainment', 'out of course goes')\n",
      "('Cảm_ơn', 'thank you', 'robbie thank thank')\n",
      "('Không', 'no', 'no no')\n",
      "('Ohhh', 'ohhhh', 'airplanes camp')\n",
      "('Wooo', 'wooo', 'mmm through')\n",
      "('Cảm_ơn', 'thank you', 'robbie thank thank')\n"
     ]
    }
   ],
   "source": [
    "for triplet in zip(test_source_list[0], test_reference_list[0], translation_output_list[0]):\n",
    "    print(triplet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n",
      "Most common source vocabs: [('là', 8210), ('tôi', 3628), ('không', 3530), ('Và', 3413), ('một', 3290), ('có', 2911), ('đó', 2883), ('Tôi', 2827), ('của', 2605), ('này', 2532)]\n",
      "Source vocab size: 6495\n",
      "Most common english vocabs: [('the', 10506), ('it', 7023), ('and', 6401), ('&apos;s', 6272), ('a', 5965), ('to', 5712), ('i', 5688), ('is', 5612), ('you', 5432), ('of', 4902)]\n",
      "English vocab size: 5897\n",
      "0 <unk>\n",
      "0 <unk>\n",
      "1 <pad>\n",
      "1 <pad>\n",
      "2 2\n",
      "2 2\n",
      "3 3\n",
      "3 3\n",
      "4 là\n",
      "4 the\n",
      "test, step: 0, average loss for current epoch: 2.6353647708892822, batch loss: 2.6353647708892822, average bleu for current epoch: 0.07290907315792883, batch bleu: 0.07290907315792883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jp4989/anaconda3/envs/nlpclass/lib/python3.6/site-packages/torchtext/data/field.py:321: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(arr, volatile=not train), lengths\n",
      "/home/jp4989/anaconda3/envs/nlpclass/lib/python3.6/site-packages/torchtext/data/field.py:322: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(arr, volatile=not train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test done. average loss for current epoch: 2.945977190046204, average bleu for current epoch: 0.05550898539445968\n",
      "('Cảm_ơn các bạn', 'thank you', 'shining gentlemen joining')\n",
      "('Ôi chúa ơi', 'oh my god', 'god oh god god')\n",
      "('Chúng_ta bắt_đầu nào', 'all right let &apos;s go', 'let starting &apos;ll begin visit broadmoor')\n",
      "('Ồ tại_sao không', 'hey why not', 'why why why aren')\n",
      "('đọc xong chứ', 'is that all', 'sees hopefully wrong telling')\n",
      "('Cám_ơn rất nhiều', 'thank you very much', 'mizzone mizzone mizzone much daniel')\n",
      "('Chúng_ta thích cải_tiến', 'we love innovation', 'wanted wanted talking computers')\n",
      "('Như_thế quá vô_lương_tâm', 'it would be unconscionable', 'this strategy became extremely extremely')\n",
      "('chúng_ta không_ngừng mâu_thuẫn', 'we &apos;re constantly running into each other', 'polio transport only dropped sexual consciousness sexual visible')\n",
      "('thế_là chúng_ta tách_biệt', 'we &apos;ve been disconnected', 'therefore lived lived walked disappeared')\n",
      "('Tôi không biết', 'i don &apos;t know', 'haven didn recommend ashamed anymore')\n",
      "('Lại là linh_cảm', 'my hunches again', 'instance example called straw')\n",
      "('Về nhà_ở đâu', 'go home to where', 'context context context within verbs')\n",
      "('Chúng_tôi rất nghèo', 'we were poor', 'our catch excited studies')\n",
      "('Bjorn Sundin', 'this is bjorn sundin', 'sebastian blah upgrade farming poetry')\n",
      "('Stephen Watt', 'this is stephen watt', 'david lewis lee lee charles')\n",
      "('Alfred Gonzalez', 'this is alfred gonzalez', 'sebastian blah vulnerability clothes dancing')\n",
      "('Kiếm tiền', 'these guys make money', 'joe condoms condoms condoms condoms')\n",
      "('Xin cảm_ơn', 'thank you', 'ladies moore brian')\n",
      "('Khá đơn_giản', 'pretty simple', 'complicated simple important')\n",
      "('Được rồi', 'okay', 'ag happening')\n",
      "('Ohhhhh wowwww', 'ohhhhh wowwww', 'sebastian knocked placed')\n",
      "('Thật đấy', 'it &apos;s true', 'seriously seriously seriously seriously')\n",
      "('1000 tuyệt_vời', '1,000 very good', 'breathing relatively phenomenal theory')\n",
      "('Được rồi', 'all right', 'because ag ag')\n",
      "('Đầu_tiên Cắt_giảm', 'the first cut', 'first first days joined')\n",
      "('thích giải_trí', 'we love entertainment', 'loving responsible environment worse')\n",
      "('Cảm_ơn', 'thank you', 'thanks scott hack')\n",
      "('Không', 'no', 'no photoshop')\n",
      "('Ohhh', 'ohhhh', 'waste forces')\n",
      "('Wooo', 'wooo', 'double borders')\n",
      "('Cảm_ơn', 'thank you', 'moore moore hack')\n"
     ]
    }
   ],
   "source": [
    "# load specific epoch of this experiment, if saved\n",
    "args.model_weights_path = '../model_weights/short/3/6'\n",
    "loss, bleu, test_source_list, test_reference_list, translation_output_list = rnn_encoder_decoder.run(args)\n",
    "for triplet in zip(test_source_list[0], test_reference_list[0], translation_output_list[0]):\n",
    "    print(triplet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n",
      "Most common source vocabs: [('的', 3925), ('我', 3262), ('是', 3127), ('这', 2377), ('了', 1938), ('我们', 1417), ('谢谢', 1356), ('你', 1340), ('它', 756), ('什么', 754)]\n",
      "Source vocab size: 3208\n",
      "Most common english vocabs: [('you', 3654), ('it', 3517), ('the', 3275), ('&apos;s', 3208), ('i', 2877), ('and', 2576), ('is', 2350), ('that', 2311), ('a', 2121), ('to', 1972)]\n",
      "English vocab size: 2592\n",
      "0 <unk>\n",
      "0 <unk>\n",
      "1 <pad>\n",
      "1 <pad>\n",
      "2 2\n",
      "2 2\n",
      "3 3\n",
      "3 3\n",
      "4 的\n",
      "4 you\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jp4989/anaconda3/envs/nlpclass/lib/python3.6/site-packages/torchtext/data/field.py:321: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(arr, volatile=not train), lengths\n",
      "/home/jp4989/anaconda3/envs/nlpclass/lib/python3.6/site-packages/torchtext/data/field.py:322: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(arr, volatile=not train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, step: 0, average loss for current epoch: 2.396838799838362, batch loss: 2.396838799838362, average bleu for current epoch: 0.06288489465766826, batch bleu: 0.06288489465766826\n",
      "test done. average loss for current epoch: 3.0924776168993233, average bleu for current epoch: 0.05582613836910575\n"
     ]
    }
   ],
   "source": [
    "parser = rnn_encoder_decoder.rnn_encoder_decoder_argparser()\n",
    "args = parser.parse_args([]) # use default settings\n",
    "args.source_lang = 'zh'\n",
    "args.data = '../data/short-sentences-zh-en/'\n",
    "args.num_encoder_layers = 2\n",
    "args.num_decoder_layers = 2\n",
    "args.test = True\n",
    "# load best weight of this experiment\n",
    "args.model_weights_path = '../model_weights/short/4'\n",
    "loss, bleu, test_source_list, test_reference_list, translation_output_list = rnn_encoder_decoder.run(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('你 可得 学着点', 'you should ask for some of that', 'your name passionate passionate your name man serious')\n",
      "('我们 爱 娱乐', 'we love entertainment', 'call call chocolate shocked')\n",
      "('我们 正在 起飞', 'we &apos;re taking off', 'ours suppose call social buildings')\n",
      "('再 做 一次', 'score them again', 'js ahead ahead ahead')\n",
      "('就 这么 简单', 'pretty simple', 'simple important important')\n",
      "('晚安 小负 负鼠', 'goodnight sweet opossum &quot;', 'hundreds rock ze asia bank')\n",
      "('这 是 Al', 'so meet al', 'this layer tradition ago')\n",
      "('哈 等 一下', 'huh hang on a moment', 'example examples example ready ready ready')\n",
      "('但 还有 一点', 'but there &apos;s another thing', 'but however problem africa problem news')\n",
      "('还是 关于 光线', 'is it something about the light', 'hands yourself yourself yourself yourself yourself tons')\n",
      "('我 不知 知道', 'i don &apos;t know', 'dad dad know gosh gosh')\n",
      "('你 从未 放手', '&quot; you have not let it go &quot;', 'you bought holding holding holding her her her her')\n",
      "('没有 任何 选择', 'no had never been an option', 'none none none none none smart smart')\n",
      "('建立 了 中心', 'centers were established', 'beginning beginning holes tape')\n",
      "('回家 回到 哪儿', 'go home to where', 'where where they learn where')\n",
      "('这 是 真的', 'it &apos;s true', 'funny embarrassing terrifying beautiful')\n",
      "('谢谢 大家', 'thank you', 'thank listening listening')\n",
      "('重点 是', 'and here &apos;s the thing', 'hg hg democracies democracies china democracies')\n",
      "('谢谢 大家', 'thank you', 'thank listening listening')\n",
      "('谢谢 大家', 'thank you very much', 'thank listening listening listening listening')\n",
      "('好 吧', 'okay', 'okay okay')\n",
      "('这 不是', 'this is not ...', 'isn unacceptable isn unacceptable isn')\n",
      "('不要 啊', 'no', 'ma sir')\n",
      "('谢谢 大家', 'thank you', 'thank listening listening')\n",
      "('谢谢 大家', 'thank you', 'thank listening listening')\n",
      "('不会 讲话', 'i didn &apos;t know how to talk about anything', 'anymore anymore anymore anymore anymore safety safety mission least exceptions')\n",
      "('我们 很穷', 'we were poor', 'shall our zoom capacity')\n",
      "('噢 哇塞', 'ohhhhh wowwww', 'ben woo woo')\n",
      "('谢谢', 'thank you', 'thanks thanks gg')\n",
      "('谢谢', 'thank you', 'thanks thanks gg')\n",
      "('噢', 'ohhhh', 'whoa whoa')\n",
      "('呜', 'wooo', 'medicine million')\n"
     ]
    }
   ],
   "source": [
    "for triplet in zip(test_source_list[0], test_reference_list[0], translation_output_list[0]):\n",
    "    print(triplet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n",
      "Most common source vocabs: [('是', 4844), ('我', 4737), ('的', 4194), ('这', 4076), ('谢', 3401), ('们', 2736), ('了', 2164), ('不', 1997), ('一', 1866), ('有', 1852)]\n",
      "Source vocab size: 2042\n",
      "Most common english vocabs: [('you', 3654), ('it', 3517), ('the', 3275), ('&apos;s', 3208), ('i', 2877), ('and', 2576), ('is', 2350), ('that', 2311), ('a', 2121), ('to', 1972)]\n",
      "English vocab size: 2592\n",
      "0 <unk>\n",
      "0 <unk>\n",
      "1 <pad>\n",
      "1 <pad>\n",
      "2 2\n",
      "2 2\n",
      "3 3\n",
      "3 3\n",
      "4 是\n",
      "4 you\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jp4989/anaconda3/envs/nlpclass/lib/python3.6/site-packages/torchtext/data/field.py:321: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(arr, volatile=not train), lengths\n",
      "/home/jp4989/anaconda3/envs/nlpclass/lib/python3.6/site-packages/torchtext/data/field.py:322: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(arr, volatile=not train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test, step: 0, average loss for current epoch: 2.323839734484266, batch loss: 2.323839734484266, average bleu for current epoch: 0.061248655038112644, batch bleu: 0.061248655038112644\n",
      "test done. average loss for current epoch: 3.1002641346869364, average bleu for current epoch: 0.0901842177655216\n",
      "('但 事 实 或 许', 'but perhaps that &apos;s not the case', 'but how possibly happen happen happening possible happening')\n",
      "('哦 我 的 天 哪', 'oh my god', 'said said said said')\n",
      "('它 会 影 响 你', 'it will get to you', 'claim yours yours many yours smoke')\n",
      "('我 们 爱 娱 乐', 'we love entertainment', 'our our our our')\n",
      "('就 这 么 简 单', 'pretty simple', 'simple simple important')\n",
      "('但 还 有 一 点', 'but there &apos;s another thing', 'look look at fact problem problem')\n",
      "('这 有 个 开 关', 'it &apos;s got one knob on off', 'these another example examples smaller another example images')\n",
      "('我 不 知 知 道', 'i don &apos;t know', 'i say saying know know')\n",
      "('你 从 未 放 手', '&quot; you have not let it go &quot;', 'cheers hello hands yourself hands hands yourself hands hands')\n",
      "('建 立 了 中 心', 'centers were established', 'china lack amount active')\n",
      "('他 沉 默 以 对', 'he retreated into silence', 'his incredibly shy perfect morning')\n",
      "('噢 我 的 上 帝', 'oh my god', 'her mine dad dad')\n",
      "('谢 谢 大 家', 'thank you', 'shukran shukran much')\n",
      "('谢 谢 大 家', 'thank you', 'shukran shukran much')\n",
      "('谢 谢 大 家', 'thank you very much', 'shukran shukran much much attention')\n",
      "('再 做 一 次', 'score them again', 'give example give some')\n",
      "('这 是 A l', 'so meet al', 'this photo called called')\n",
      "('哈 等 一 下', 'huh hang on a moment', 'carefully carefully next starts four carefully')\n",
      "('谢 谢 大 家', 'thank you', 'shukran shukran much')\n",
      "('谢 谢 大 家', 'thank you', 'shukran shukran much')\n",
      "('不 会 讲 话', 'i didn &apos;t know how to talk about anything', 'don &apos;t worry worry worry don &apos;t no no happen')\n",
      "('我 们 很 穷', 'we were poor', 'we call call call')\n",
      "('这 是 真 的', 'it &apos;s true', 'beauty is simple simple')\n",
      "('重 点 是', 'and here &apos;s the thing', 'ze serious emotion clouds clouds complex')\n",
      "('这 不 是', 'this is not ...', 'isn isn wasn isn isn')\n",
      "('不 要 啊', 'no', 'don &apos;t')\n",
      "('噢 哇 塞', 'ohhhhh wowwww', 'hg lady reaction')\n",
      "('谢 谢', 'thank you', 'thanks thank thank')\n",
      "('好 吧', 'okay', 'ok ok')\n",
      "('谢 谢', 'thank you', 'thanks thank thank')\n",
      "('噢', 'ohhhh', 'morning morning')\n",
      "('呜', 'wooo', 'seven minutes')\n"
     ]
    }
   ],
   "source": [
    "parser = rnn_encoder_decoder.rnn_encoder_decoder_argparser()\n",
    "args = parser.parse_args([]) # use default settings\n",
    "args.source_lang = 'zh'\n",
    "args.data = '../data/short-sentences-zh-en/'\n",
    "args.num_encoder_layers = 2\n",
    "args.num_decoder_layers = 2\n",
    "args.test = True\n",
    "# load best weight of this experiment\n",
    "args.model_weights_path = '../model_weights/short/5'\n",
    "args.split_chinese_into_characters = True\n",
    "loss, bleu, test_source_list, test_reference_list, translation_output_list = rnn_encoder_decoder.run(args)\n",
    "for triplet in zip(test_source_list[0], test_reference_list[0], translation_output_list[0]):\n",
    "    print(triplet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlpclass]",
   "language": "python",
   "name": "conda-env-nlpclass-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
